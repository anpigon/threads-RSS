<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>choi.openai on Threads</title><link>https://www.threads.net/@craigmod</link><description>Threads via RSS</description><language>en</language><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>진짜 올해 가장 잘한 일은 스레드에서 이분 팔로우 한 것입니다.</title><link>https://www.threads.net/@choi.openai/post/DHgDvz5IynE</link><description>진짜 올해 가장 잘한 일은 스레드에서 이분 팔로우 한 것입니다.</description></item><item><title>실질적인 위험은 AI보다 로봇일 수 있습니다.

세계 최대 광고 회사인 WPP가 NVIDIA, 보스턴다이내믹스(Boston Dynamics), 캐논(Canon)과 협력하여 로봇 지원 촬영과 가상 광고 제작을 연구하고 있습니다. 

촬영 현장에서 아틀라스(Atlas)의 멋진 모습도 함께 담겨있네요.

에이전틱AI 이후는 피지컬AI 입니다. 전 분야 아인슈타인 지능이 탑재된 로봇을 상상해보세요.</title><link>https://www.threads.net/@choi.openai/post/DHf1gX-vCX9</link><description>실질적인 위험은 AI보다 로봇일 수 있습니다.

세계 최대 광고 회사인 WPP가 NVIDIA, 보스턴다이내믹스(Boston Dynamics), 캐논(Canon)과 협력하여 로봇 지원 촬영과 가상 광고 제작을 연구하고 있습니다. 

촬영 현장에서 아틀라스(Atlas)의 멋진 모습도 함께 담겨있네요.

에이전틱AI 이후는 피지컬AI 입니다. 전 분야 아인슈타인 지능이 탑재된 로봇을 상상해보세요.</description></item><item><title>이거 꼭 따라해보세요. 삶의 질이 달라집니다.

제가 정말 유용하게 사용하는 클로드 시각화 방법입니다.

바로 Youtube MCP와 같이 사용하는 것인데요, 영상 자료에서 스크립트를 받아와서 바로 시각화를 진행할 수 있습니다.

해외 자료나 컨터펀스 요약하기에 정말 유용합니다.</title><link>https://www.threads.net/@choi.openai/post/DHfWftvAwvW</link><description>이거 꼭 따라해보세요. 삶의 질이 달라집니다.

제가 정말 유용하게 사용하는 클로드 시각화 방법입니다.

바로 Youtube MCP와 같이 사용하는 것인데요, 영상 자료에서 스크립트를 받아와서 바로 시각화를 진행할 수 있습니다.

해외 자료나 컨터펀스 요약하기에 정말 유용합니다.</description></item><item><title>MCP는 클로드 데스크톱 앱에서 가능합니다.

https://smithery.ai/ 에서 원하는 MCP를 찾아 설치하시면 됩니다.</title><link>https://www.threads.net/@choi.openai/post/DHfWgtOPaTh</link><description>MCP는 클로드 데스크톱 앱에서 가능합니다.

https://smithery.ai/ 에서 원하는 MCP를 찾아 설치하시면 됩니다.</description></item><item><title>샘 알트만: "나는 우리가 최초의 AGI를 출시해도, 아무도 크게 신경 쓰지 않을 수 있다고 꽤 진심으로 믿는다."</title><link>https://www.threads.net/@choi.openai/post/DHfLtZROqr8</link><description>샘 알트만: "나는 우리가 최초의 AGI를 출시해도, 아무도 크게 신경 쓰지 않을 수 있다고 꽤 진심으로 믿는다."</description></item><item><title>풀영상 :
https://www.youtube.com/watch?v=c0NqpG--Pzw</title><link>https://www.threads.net/@choi.openai/post/DHfLyB8PZUL</link><description>풀영상 :
https://www.youtube.com/watch?v=c0NqpG--Pzw</description></item><item><title>구글 Gemini를 이용한 바이브드로잉은 정말 미쳤습니다.</title><link>https://www.threads.net/@choi.openai/post/DHfAP0ppQ21</link><description>구글 Gemini를 이용한 바이브드로잉은 정말 미쳤습니다.</description></item><item><title>이모티콘도 만들기 너무 쉬운 시대입니다.</title><link>https://www.threads.net/@choi.openai/post/DHfDJeAsm8p</link><description>이모티콘도 만들기 너무 쉬운 시대입니다.</description></item><item><title>AI시대, 당신은 책임감 있는 사람인가요?

AI 에이전트가 발전하고 AI 에이전트가 사용할 수 있는 도구와 권한이 늘어날 떄마다, 이제 서비스를 사용함에 있어 무언가를 "허용"하거나 "동의"하는 경우가 많이 늘어나고 있다.

그리고 우리가 그러한 버튼을 누름에 있어 책임의 일부분을 AI와 나누고 있다는 점을 생각해볼 필요가 있다.

기술의 편의성이 증가하면서 자신의 책임을 얼마나 AI에게 위임하고 있는지 의식하지 못하는 경우가 많다.

최근 개발 분야에서는 전문 지식 없이 AI에게 전적으로 의지하는 '바이브 코딩'이 큰 인기를 끌고 있다.

바이브 코딩은 오픈AI의 공동 창립자이자 전 테슬라 AI 리더인 안드레이 카파시가 처음 소개한 용어로 AI에게 전적으로 의존하여 코딩을 모르는 사람도 빠르게 소프트웨어를 개발할 수 있게 하여, 개발 장벽을 낮추고 빠르게 결과물을 얻을 수 있다는 장점을 제공한다.

이어서 👇🏻</title><link>https://www.threads.net/@choi.openai/post/DHe4DHAThOa</link><description>AI시대, 당신은 책임감 있는 사람인가요?

AI 에이전트가 발전하고 AI 에이전트가 사용할 수 있는 도구와 권한이 늘어날 떄마다, 이제 서비스를 사용함에 있어 무언가를 "허용"하거나 "동의"하는 경우가 많이 늘어나고 있다.

그리고 우리가 그러한 버튼을 누름에 있어 책임의 일부분을 AI와 나누고 있다는 점을 생각해볼 필요가 있다.

기술의 편의성이 증가하면서 자신의 책임을 얼마나 AI에게 위임하고 있는지 의식하지 못하는 경우가 많다.

최근 개발 분야에서는 전문 지식 없이 AI에게 전적으로 의지하는 '바이브 코딩'이 큰 인기를 끌고 있다.

바이브 코딩은 오픈AI의 공동 창립자이자 전 테슬라 AI 리더인 안드레이 카파시가 처음 소개한 용어로 AI에게 전적으로 의존하여 코딩을 모르는 사람도 빠르게 소프트웨어를 개발할 수 있게 하여, 개발 장벽을 낮추고 빠르게 결과물을 얻을 수 있다는 장점을 제공한다.

이어서 👇🏻</description></item><item><title>나 역시 Cursor와 같은 AI 기반 프로그래밍 에디터를 사용하면서 터미널 작업 실행 시 매번 나타나는 "실행 권한" 요청이 번거로워 결국 auto-run을 활성화하여 사용하는 모습을 보게 되는데, 처음엔 이 결정이 단순히 작업 효율성을 높이는 작은 변화라고만 여겼지만, 시간이 지날수록 나의 결정 권한이 점점 더 AI로 넘어가고 있다는 사실을 깨닫고 있는 것 같다.

이러한 편리함 앞에서 우리의 책임감은 과연 충분히 유지될 수 있을까? 기술 사용에 따른 책임과 권한 위임의 문제는 과거보다 더 중요하게 대두되고 있다.

"동의" 버튼을 클릭한 것은 나 자신이지만, 이후의 결정과 결과가 AI의 손에 달리면서 심리적으로 책임감을 느끼기 어렵게 되는 경향이 있다.

결국 AI가 오류를 일으키거나 예상치 못한 결과를 초래했을 때, 책임 소재를 AI에 전가하려는 심리가 생겨난다.

이러한 현상은 소프트웨어 개발 분야에만 국한되지 않는다. 👇🏻</title><link>https://www.threads.net/@choi.openai/post/DHe4DjGzlMw</link><description>나 역시 Cursor와 같은 AI 기반 프로그래밍 에디터를 사용하면서 터미널 작업 실행 시 매번 나타나는 "실행 권한" 요청이 번거로워 결국 auto-run을 활성화하여 사용하는 모습을 보게 되는데, 처음엔 이 결정이 단순히 작업 효율성을 높이는 작은 변화라고만 여겼지만, 시간이 지날수록 나의 결정 권한이 점점 더 AI로 넘어가고 있다는 사실을 깨닫고 있는 것 같다.

이러한 편리함 앞에서 우리의 책임감은 과연 충분히 유지될 수 있을까? 기술 사용에 따른 책임과 권한 위임의 문제는 과거보다 더 중요하게 대두되고 있다.

"동의" 버튼을 클릭한 것은 나 자신이지만, 이후의 결정과 결과가 AI의 손에 달리면서 심리적으로 책임감을 느끼기 어렵게 되는 경향이 있다.

결국 AI가 오류를 일으키거나 예상치 못한 결과를 초래했을 때, 책임 소재를 AI에 전가하려는 심리가 생겨난다.

이러한 현상은 소프트웨어 개발 분야에만 국한되지 않는다. 👇🏻</description></item><item><title>오픈AI의 비디오 생성 모델 Sora 이제 무제한 생성 가능!!

오픈AI의 Sora가 크레딧 제도를 폐지하고 무제한 생성이 가능하도록 바꼈습니다.

이전에도 Relaxed 모드로 무제한 생성이 가능했지만, 크레딧 자체를 삭제한 부분은 주목할만해 보입니다.</title><link>https://www.threads.net/@choi.openai/post/DHexFsZIYsc</link><description>오픈AI의 비디오 생성 모델 Sora 이제 무제한 생성 가능!!

오픈AI의 Sora가 크레딧 제도를 폐지하고 무제한 생성이 가능하도록 바꼈습니다.

이전에도 Relaxed 모드로 무제한 생성이 가능했지만, 크레딧 자체를 삭제한 부분은 주목할만해 보입니다.</description></item><item><title>Grok에서 이미지 편집 기능을 출시했습니다.

이제 이미지를 업로드하고, 변경하고 싶은 내용을 설명하기만 하면 쉽게 편집할 수 있습니다.

xAI가 빠르게 발전하고 있습니다.

다만 테스트 결과 구글 네이티브 이미지 편집보다는 아쉬운 결과를 보여줍니다.</title><link>https://www.threads.net/@choi.openai/post/DHerhbCzH6y</link><description>Grok에서 이미지 편집 기능을 출시했습니다.

이제 이미지를 업로드하고, 변경하고 싶은 내용을 설명하기만 하면 쉽게 편집할 수 있습니다.

xAI가 빠르게 발전하고 있습니다.

다만 테스트 결과 구글 네이티브 이미지 편집보다는 아쉬운 결과를 보여줍니다.</description></item><item><title>현재 이미지 편집 기능은 X 플랫폼에서만 지원됩니다.
* grok 사이트와 앱은 현재 준비중</title><link>https://www.threads.net/@choi.openai/post/DHerweYTtWY</link><description>현재 이미지 편집 기능은 X 플랫폼에서만 지원됩니다.
* grok 사이트와 앱은 현재 준비중</description></item><item><title>LoRA가 필요 없이 단일 이미지로 생성이 가능한 시스템은 굉장히 위험합니다.

막을수 없기에 알고 있어야하는 내용이라고 생각합니다.
지난번 그 사례가 아직도 기억에 남더라구요.

내 주변 사람들의 사진으로 온디바이스 초개인화 광고 마케팅이 진행된다면 구매하지 않을 사람이 있겠는가 하는 말.</title><link>https://www.threads.net/@choi.openai/post/DHdpcMuvsJL</link><description>LoRA가 필요 없이 단일 이미지로 생성이 가능한 시스템은 굉장히 위험합니다.

막을수 없기에 알고 있어야하는 내용이라고 생각합니다.
지난번 그 사례가 아직도 기억에 남더라구요.

내 주변 사람들의 사진으로 온디바이스 초개인화 광고 마케팅이 진행된다면 구매하지 않을 사람이 있겠는가 하는 말.</description></item><item><title>후.. AI 소식이 별로 없네요.

주말에는 활용 방법과 새로운 AI 툴 업데이트 차트가 업로드될 예정입니다!</title><link>https://www.threads.net/@choi.openai/post/DHderh0vxOe</link><description>후.. AI 소식이 별로 없네요.

주말에는 활용 방법과 새로운 AI 툴 업데이트 차트가 업로드될 예정입니다!</description></item><item><title>안무도 AI가 생성하는 시대가 올까요?

워싱턴 대학교에서 이번 주에 공개한 음악 기반 춤 영상 생성 모델인 MusicInfuser는 주어진 음악에 맞춰 자동으로 춤 영상을 생성할 수 있습니다.

음악과 춤의 동기화가 매우 잘 이루어지는 것처럼 보이는데요.

이 모델은 개인 춤, 듀엣 춤, 그룹 춤을 생성할 수 있으며, 다양한 종류의 음악에 적응 가능합니다.

사용자는 서로 다른 음악과 텍스트 프롬프트를 통해 춤 스타일, 장면, 춤추는 인원 수 등을 조절할 수 있습니다.</title><link>https://www.threads.net/@choi.openai/post/DHdT8WHvd3_</link><description>안무도 AI가 생성하는 시대가 올까요?

워싱턴 대학교에서 이번 주에 공개한 음악 기반 춤 영상 생성 모델인 MusicInfuser는 주어진 음악에 맞춰 자동으로 춤 영상을 생성할 수 있습니다.

음악과 춤의 동기화가 매우 잘 이루어지는 것처럼 보이는데요.

이 모델은 개인 춤, 듀엣 춤, 그룹 춤을 생성할 수 있으며, 다양한 종류의 음악에 적응 가능합니다.

사용자는 서로 다른 음악과 텍스트 프롬프트를 통해 춤 스타일, 장면, 춤추는 인원 수 등을 조절할 수 있습니다.</description></item><item><title>깃허브 :
https://github.com/SusungHong/MusicInfuser</title><link>https://www.threads.net/@choi.openai/post/DHdT-SnP0V5</link><description>깃허브 :
https://github.com/SusungHong/MusicInfuser</description></item><item><title>와우.. AI 영화 제작이 얼마나 쉬워지고 있는지 봐보세요.

SkyReels AI는 영화 대본, 스토리보드, 일관된 캐릭터, 비디오, 음성, 입술 싱크 및 음악을 자동으로 생성할 수 있습니다. 

또한, 이 새로운 AI 비디오 편집도구는 영화를 스스로 편집할 수 있습니다. 

이런 시스템을 미리 구축하고 있는 플랫폼 사업자들은 비디오 생성 AI와 언어모델 성능이 증가할 수록 더 큰 혜택을 받을 수 있을 것 같습니다.</title><link>https://www.threads.net/@choi.openai/post/DHdMGKXPydN</link><description>와우.. AI 영화 제작이 얼마나 쉬워지고 있는지 봐보세요.

SkyReels AI는 영화 대본, 스토리보드, 일관된 캐릭터, 비디오, 음성, 입술 싱크 및 음악을 자동으로 생성할 수 있습니다. 

또한, 이 새로운 AI 비디오 편집도구는 영화를 스스로 편집할 수 있습니다. 

이런 시스템을 미리 구축하고 있는 플랫폼 사업자들은 비디오 생성 AI와 언어모델 성능이 증가할 수록 더 큰 혜택을 받을 수 있을 것 같습니다.</description></item><item><title>1/ 스크립트 작성

사용자는 자신의 아이디어를 입력하거나 이야기를 업로드할 수 있으며, 이 시스템은 이를 바탕으로 전문적인 각본으로 변환합니다.

나중에 사용자의 이야기를 기반으로 캐릭터와 스토리보드를 설계할 수 있습니다.</title><link>https://www.threads.net/@choi.openai/post/DHdNOSRvwpB</link><description>1/ 스크립트 작성

사용자는 자신의 아이디어를 입력하거나 이야기를 업로드할 수 있으며, 이 시스템은 이를 바탕으로 전문적인 각본으로 변환합니다.

나중에 사용자의 이야기를 기반으로 캐릭터와 스토리보드를 설계할 수 있습니다.</description></item><item><title>Felo의 Deep Search 3.1이 출시되었습니다.
이번 업데이트를 통해 검색의 정확도와 정보량이 크게 향상되었는데요.

HLE(Humanity's Last Exam) 스코어가 28%에서 31.2%로 증가하여 더 정교한 이해를 이루었고, Pro(퀵)와 비교했을 때 복잡한 지식 영역에서의 성능이 눈에 띄게 개선되었습니다.
Pro(퀵)의 정답률은 68.25%인 반면, Pro(딥)의 정답률은 92.5%를 기록했습니다. 

또한, 검색 결과의 정보가 더욱 풍부해져 더 깊은 통찰력과 다각적인 정보를 제공하여 검색의 질이 크게 향상되었습니다.</title><link>https://www.threads.net/@choi.openai/post/DHdEQJ3viXD</link><description>Felo의 Deep Search 3.1이 출시되었습니다.
이번 업데이트를 통해 검색의 정확도와 정보량이 크게 향상되었는데요.

HLE(Humanity's Last Exam) 스코어가 28%에서 31.2%로 증가하여 더 정교한 이해를 이루었고, Pro(퀵)와 비교했을 때 복잡한 지식 영역에서의 성능이 눈에 띄게 개선되었습니다.
Pro(퀵)의 정답률은 68.25%인 반면, Pro(딥)의 정답률은 92.5%를 기록했습니다. 

또한, 검색 결과의 정보가 더욱 풍부해져 더 깊은 통찰력과 다각적인 정보를 제공하여 검색의 질이 크게 향상되었습니다.</description></item><item><title>MCP의 무서운 점은 과대광고에 힘입은 오픈소스 생택계인 것 같습니다.

이번에는 에이블톤과 연동된 MCP가 새롭게 나왔는데요.
해당 영상에서는 프롬프트만으로 80년대 신스웨이브 음악을 생성하는 모습을 보여줍니다.

물론, 요즘 음악AI가 상당히 발전해 트랙을 만들어야하는 경우를 제외하고는 큰 수요는 없을 것이라고 생각은 듭니다만.. 경각심이나 활용성의 무궁무진함을 보여주기 위한 사례로는 충분히 좋아보입니다.

언어모델이 발전되는 지능의 방향은 이런 부분에서 들어나는 것 같습니다.

현재의 에이전트 시스템들은 인간이 구축해 놓은 시스템을 활용하는 방법으로 발전되고 있지만, 어느 순간부터는 시스템 자체가 에이전트가 활용하기 좋게 발전될 가능성이 높습니다.

가끔 AI가 이건 못하던데.. 라는 의견을 가진 소수 분야의 주장이 있지만, 아직 못하는 것과 하지 못하는 것에 대한 명확한 구분이 필요합니다.</title><link>https://www.threads.net/@choi.openai/post/DHc8IzcNxOZ</link><description>MCP의 무서운 점은 과대광고에 힘입은 오픈소스 생택계인 것 같습니다.

이번에는 에이블톤과 연동된 MCP가 새롭게 나왔는데요.
해당 영상에서는 프롬프트만으로 80년대 신스웨이브 음악을 생성하는 모습을 보여줍니다.

물론, 요즘 음악AI가 상당히 발전해 트랙을 만들어야하는 경우를 제외하고는 큰 수요는 없을 것이라고 생각은 듭니다만.. 경각심이나 활용성의 무궁무진함을 보여주기 위한 사례로는 충분히 좋아보입니다.

언어모델이 발전되는 지능의 방향은 이런 부분에서 들어나는 것 같습니다.

현재의 에이전트 시스템들은 인간이 구축해 놓은 시스템을 활용하는 방법으로 발전되고 있지만, 어느 순간부터는 시스템 자체가 에이전트가 활용하기 좋게 발전될 가능성이 높습니다.

가끔 AI가 이건 못하던데.. 라는 의견을 가진 소수 분야의 주장이 있지만, 아직 못하는 것과 하지 못하는 것에 대한 명확한 구분이 필요합니다.</description></item><item><title>엘론 머스크는 2025년 1분기 테슬라 전체 회의에서 다음과 같이 말했습니다.

“올해 우리는 약 5,000대의 옵티머스 로봇을 제작할 수 있기를 희망합니다.”

“내년에는 대략 50,000대 정도가 될 것입니다.”

“옵티머스 로봇은 내년 하반기에 테슬라가 통제하지 않는 환경에서도 사용될 예정입니다.”

“먼저 옵티머스 로봇은 테슬라 직원들에게 제공할 것입니다.”</title><link>https://www.threads.net/@choi.openai/post/DHc0Q4WPXZy</link><description>엘론 머스크는 2025년 1분기 테슬라 전체 회의에서 다음과 같이 말했습니다.

“올해 우리는 약 5,000대의 옵티머스 로봇을 제작할 수 있기를 희망합니다.”

“내년에는 대략 50,000대 정도가 될 것입니다.”

“옵티머스 로봇은 내년 하반기에 테슬라가 통제하지 않는 환경에서도 사용될 예정입니다.”

“먼저 옵티머스 로봇은 테슬라 직원들에게 제공할 것입니다.”</description></item><item><title>일론 머스크는 새로운 옵티머스 손이 22개의 자유도를 가지고 있으며, 새로운 팔꿈치 부분이 현재 생산에 들어갔다고 발표했습니다.</title><link>https://www.threads.net/@choi.openai/post/DHc4qUtPWbI</link><description>일론 머스크는 새로운 옵티머스 손이 22개의 자유도를 가지고 있으며, 새로운 팔꿈치 부분이 현재 생산에 들어갔다고 발표했습니다.</description></item><item><title>StarVector가 허깅페이스에서 공개되었습니다.

StarVector는 이미지와 텍스트로부터 SVG 코드를 생성하기 위한 파운데이션 모델입니다.

이 모델은 비전-언어 모델링 아키텍처를 활용하여 시각적 입력과 텍스트 입력을 모두 이해하며, 고품질 벡터화와 텍스트 유도 SVG 생성을 가능하게 합니다.</title><link>https://www.threads.net/@choi.openai/post/DHcublBv94z</link><description>StarVector가 허깅페이스에서 공개되었습니다.

StarVector는 이미지와 텍스트로부터 SVG 코드를 생성하기 위한 파운데이션 모델입니다.

이 모델은 비전-언어 모델링 아키텍처를 활용하여 시각적 입력과 텍스트 입력을 모두 이해하며, 고품질 벡터화와 텍스트 유도 SVG 생성을 가능하게 합니다.</description></item><item><title>모델 :
https://huggingface.co/collections/starvector/starvector-models-6783b22c7bd4b43d13cb5289</title><link>https://www.threads.net/@choi.openai/post/DHcuerdP4gR</link><description>모델 :
https://huggingface.co/collections/starvector/starvector-models-6783b22c7bd4b43d13cb5289</description></item><item><title>“샘 알트만은 아마도 잠을 설치고 있을 것이다.”

카이푸 리는 오픈 소스의 성공이 불가피하다고 보며, 폐쇄형 인공지능 모델의 장기적인 생존 가능성을 의심하고 있습니다.

현실은 불가피하게 다가오고 있습니다.
DeepSeek는 오픈AI의 연간 70억 달러 비용의 단 2%로 운영되고 있습니다.</title><link>https://www.threads.net/@choi.openai/post/DHcSavtPQRT</link><description>“샘 알트만은 아마도 잠을 설치고 있을 것이다.”

카이푸 리는 오픈 소스의 성공이 불가피하다고 보며, 폐쇄형 인공지능 모델의 장기적인 생존 가능성을 의심하고 있습니다.

현실은 불가피하게 다가오고 있습니다.
DeepSeek는 오픈AI의 연간 70억 달러 비용의 단 2%로 운영되고 있습니다.</description></item><item><title>퍼플렉시티에서 Deep Research의 업데이트된 버전을 작업 중입니다(다음 주에 출시될 예정).

이번 업데이트에서는 더 많은 계산을 처리하고, 더 긴 생각을 하고, 더 상세한 답변을 제시하며, 코드 실행을 사용할 수 있고, 인라인 차트를 렌더링할 수 있게 될 예정입니다.</title><link>https://www.threads.net/@choi.openai/post/DHcOgSOP4Ti</link><description>퍼플렉시티에서 Deep Research의 업데이트된 버전을 작업 중입니다(다음 주에 출시될 예정).

이번 업데이트에서는 더 많은 계산을 처리하고, 더 긴 생각을 하고, 더 상세한 답변을 제시하며, 코드 실행을 사용할 수 있고, 인라인 차트를 렌더링할 수 있게 될 예정입니다.</description></item><item><title>많은 분들의 뜨거운 관심으로 오픈 채팅을 추가로 개설하게되었습니다.

하루 세 번(오류로 안보내질 수도 있음) 논문, 소식, 프로덕트 뉴스를 보내드립니다

* 자동화된 방이며, 방장이외 대화를 할 수 없으니 참고 부탁드립니다.</title><link>https://www.threads.net/@choi.openai/post/DHcGsX0Tdgb</link><description>많은 분들의 뜨거운 관심으로 오픈 채팅을 추가로 개설하게되었습니다.

하루 세 번(오류로 안보내질 수도 있음) 논문, 소식, 프로덕트 뉴스를 보내드립니다

* 자동화된 방이며, 방장이외 대화를 할 수 없으니 참고 부탁드립니다.</description></item><item><title>오픈채팅 :

CHOI의 인공지능 뉴스레터
https://open.kakao.com/o/gDJsRCfh</title><link>https://www.threads.net/@choi.openai/post/DHcGtmdzLw-</link><description>오픈채팅 :

CHOI의 인공지능 뉴스레터
https://open.kakao.com/o/gDJsRCfh</description></item><item><title>오픈AI, 새로운 오디오 모델 3종 발표! 음성 에이전트 시대 열어가나?

오픈AI가 이번 라이브 스트림에서 3가지 오디오 모델을 발표했습니다.

TTS(Text To Speach) 모델 1개
- gpt-4o-mini-tts
STT(Speach To Text) 모델 2개
- gpt-4o-transcribe, gpt-4o-mini-transcribe

가격도 기존 whisper과 동일하며 뛰어난 인식 성능으로 새로운 SOTA 모델을 보여주는 것 같습니다.

또한, 음성을 통한 에이전트 기능을 시연하며 앞으로 시장의 변화도 보여주는 것 같은데요.
 
그럼 각 세부 내용 함께 살펴보시죠 👇🏻</title><link>https://www.threads.net/@choi.openai/post/DHbe2OMt7jN</link><description>오픈AI, 새로운 오디오 모델 3종 발표! 음성 에이전트 시대 열어가나?

오픈AI가 이번 라이브 스트림에서 3가지 오디오 모델을 발표했습니다.

TTS(Text To Speach) 모델 1개
- gpt-4o-mini-tts
STT(Speach To Text) 모델 2개
- gpt-4o-transcribe, gpt-4o-mini-transcribe

가격도 기존 whisper과 동일하며 뛰어난 인식 성능으로 새로운 SOTA 모델을 보여주는 것 같습니다.

또한, 음성을 통한 에이전트 기능을 시연하며 앞으로 시장의 변화도 보여주는 것 같은데요.
 
그럼 각 세부 내용 함께 살펴보시죠 👇🏻</description></item><item><title>1/ 오디오 모델 발표</title><link>https://www.threads.net/@choi.openai/post/DHbe3ZJpuO4</link><description>1/ 오디오 모델 발표</description></item><item><title>클로드에서 공식적으로 웹 검색 기능을 지원합니다!

앤트로픽의 Claude가 웹 검색 기능을 도입했습니다.
이제 Claude는 인터넷에서 실시간 정보를 검색해 더 최신의 답변을 제공할 수 있게 되었는데요.

이 기능은 미국의 유료 사용자 대상으로 프리뷰로 제공되고 있으며, 설정에서 "web search"를 활성화하면 Claude 3.7 Sonnet 모델부터 이용할 수 있습니다.</title><link>https://www.threads.net/@choi.openai/post/DHbbWITtxsH</link><description>클로드에서 공식적으로 웹 검색 기능을 지원합니다!

앤트로픽의 Claude가 웹 검색 기능을 도입했습니다.
이제 Claude는 인터넷에서 실시간 정보를 검색해 더 최신의 답변을 제공할 수 있게 되었는데요.

이 기능은 미국의 유료 사용자 대상으로 프리뷰로 제공되고 있으며, 설정에서 "web search"를 활성화하면 Claude 3.7 Sonnet 모델부터 이용할 수 있습니다.</description></item><item><title>공식 블로그 :
https://www.anthropic.com/news/web-search</title><link>https://www.threads.net/@choi.openai/post/DHbbkpcPEh8</link><description>공식 블로그 :
https://www.anthropic.com/news/web-search</description></item><item><title>오픈AI, 새벽 2시 라이브 스트림 진행

가장 빨리 업데이트 해드리겠습니다 🫡</title><link>https://www.threads.net/@choi.openai/post/DHbOy_dv9ni</link><description>오픈AI, 새벽 2시 라이브 스트림 진행

가장 빨리 업데이트 해드리겠습니다 🫡</description></item><item><title>와 Krea 미친 업데이트!!

KREA AI에서 AI 영상 생성 기능을 한 단계 발전시킨 "Video Training"을 선보였습니다. 

이제 사용자는 Wan 2.1 모델을 직접 훈련시킬 수 있으며, 자신만의 영상 스타일, 동작, 특정 객체 등을 학습시킬 수 있눈데요.

즉, 원하는 요소를 모델에 반영하여 보다 자유로운 콘텐츠 제작이 가능해졌습니다.

AI 기반 영상 생성 기술이 점점 세밀한 맞춤형 조정이 가능해지고 있는 만큼, 앞으로 어떤 혁신이 이어질지 기대됩니다.

제작방법 👇🏻</title><link>https://www.threads.net/@choi.openai/post/DHbLSxATQwx</link><description>와 Krea 미친 업데이트!!

KREA AI에서 AI 영상 생성 기능을 한 단계 발전시킨 "Video Training"을 선보였습니다. 

이제 사용자는 Wan 2.1 모델을 직접 훈련시킬 수 있으며, 자신만의 영상 스타일, 동작, 특정 객체 등을 학습시킬 수 있눈데요.

즉, 원하는 요소를 모델에 반영하여 보다 자유로운 콘텐츠 제작이 가능해졌습니다.

AI 기반 영상 생성 기술이 점점 세밀한 맞춤형 조정이 가능해지고 있는 만큼, 앞으로 어떤 혁신이 이어질지 기대됩니다.

제작방법 👇🏻</description></item><item><title>시작하려면 krea.ai/train에 방문하여 "비디오"를 선택한 후, 이미지나 비디오 셋을 업로드하세요. 

이미지를 사용할 경우 AI는 스타일에 집중하고, 비디오를 사용할 경우 시각적 스타일과 동작 모두에 집중하게 됩니다.</title><link>https://www.threads.net/@choi.openai/post/DHbLZz-zJSO</link><description>시작하려면 krea.ai/train에 방문하여 "비디오"를 선택한 후, 이미지나 비디오 셋을 업로드하세요. 

이미지를 사용할 경우 AI는 스타일에 집중하고, 비디오를 사용할 경우 시각적 스타일과 동작 모두에 집중하게 됩니다.</description></item><item><title>Figma 디자인으로 끝내지 마세요!

지난주 bolt에서 figma 연동 기능을 출시했는데요.
이제 디자인 작업물을 기반으로 빠르게 랜딩페이지를 만들어 시연할 수 있습니다.
Supabase로 백엔드 구현까지 가능하니 디자인으로 멈추지 말고 시연 가능한 서비스까지 해보는 것은 어떨까요?

아래 제작예시 3가지 소개해드립니다! 👇🏻</title><link>https://www.threads.net/@choi.openai/post/DHauFIisyzH</link><description>Figma 디자인으로 끝내지 마세요!

지난주 bolt에서 figma 연동 기능을 출시했는데요.
이제 디자인 작업물을 기반으로 빠르게 랜딩페이지를 만들어 시연할 수 있습니다.
Supabase로 백엔드 구현까지 가능하니 디자인으로 멈추지 말고 시연 가능한 서비스까지 해보는 것은 어떨까요?

아래 제작예시 3가지 소개해드립니다! 👇🏻</description></item><item><title>2/</title><link>https://www.threads.net/@choi.openai/post/DHauFytAVHi</link><description>2/</description></item></channel></rss>